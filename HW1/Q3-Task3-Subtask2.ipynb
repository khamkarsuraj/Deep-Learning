{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712779af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 21:54:38.959596: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/var/folders/x1/3fzzpt8s0wb1z5zdd_z53mxr0000gn/T/ipykernel_1448/1559922479.py:10: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-whitegrid')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b896f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab MNIST dataset\n",
    "trainingSet = datasets.MNIST('', train=True, download=False, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "testingSet = datasets.MNIST('', train=False, download=False, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8433b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set different batch sizes for each of the 5 different models\n",
    "batchSizes = [5, 25, 125, 500, 1500]\n",
    "train1 = torch.utils.data.DataLoader(trainingSet, batch_size=batchSizes[0], shuffle=True)\n",
    "test1 = torch.utils.data.DataLoader(testingSet, batch_size=batchSizes[0], shuffle=True)\n",
    "train2 = torch.utils.data.DataLoader(trainingSet, batch_size=batchSizes[1], shuffle=True)\n",
    "test2 = torch.utils.data.DataLoader(testingSet, batch_size=batchSizes[1], shuffle=True)\n",
    "train3 = torch.utils.data.DataLoader(trainingSet, batch_size=batchSizes[2], shuffle=True)\n",
    "test3 = torch.utils.data.DataLoader(testingSet, batch_size=batchSizes[2], shuffle=True)\n",
    "train4 = torch.utils.data.DataLoader(trainingSet, batch_size=batchSizes[3], shuffle=True)\n",
    "test4 = torch.utils.data.DataLoader(testingSet, batch_size=batchSizes[3], shuffle=True)\n",
    "train5 = torch.utils.data.DataLoader(trainingSet, batch_size=batchSizes[4], shuffle=True)\n",
    "test5 = torch.utils.data.DataLoader(testingSet, batch_size=batchSizes[4], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893e5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1 - 2 Hidden layer / 16640 Parameters\n",
    "class model1 (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 20)\n",
    "        self.fc2 = nn.Linear(20, 30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, val):\n",
    "        val = F.relu(self.fc1(val))\n",
    "        val = F.relu(self.fc2(val))\n",
    "        val = self.fc3(val)\n",
    "        return val\n",
    "\n",
    "# model 2 - 2 Hidden layer / 16640 Parameters\n",
    "class model2 (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 20)\n",
    "        self.fc2 = nn.Linear(20, 30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, val):\n",
    "        val = F.relu(self.fc1(val))\n",
    "        val = F.relu(self.fc2(val))\n",
    "        val = self.fc3(val)\n",
    "        return val\n",
    "\n",
    "# model 3 - 2 Hidden layer / 16640 Parameters\n",
    "class model3 (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 20)\n",
    "        self.fc2 = nn.Linear(20, 30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, val):\n",
    "        val = F.relu(self.fc1(val))\n",
    "        val = F.relu(self.fc2(val))\n",
    "        val = self.fc3(val)\n",
    "        return val\n",
    "# model 4 - 2 Hidden layer / 16640 Parameters\n",
    "class model4 (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 20)\n",
    "        self.fc2 = nn.Linear(20, 30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, val):\n",
    "        val = F.relu(self.fc1(val))\n",
    "        val = F.relu(self.fc2(val))\n",
    "        val = self.fc3(val)\n",
    "        return val\n",
    "    \n",
    "# model 5 - 2 Hidden layer / 16640 Parameters\n",
    "class model5 (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 20)\n",
    "        self.fc2 = nn.Linear(20, 30)\n",
    "        self.fc3 = nn.Linear(30, 10)\n",
    "\n",
    "    def forward(self, val):\n",
    "        val = F.relu(self.fc1(val))\n",
    "        val = F.relu(self.fc2(val))\n",
    "        val = self.fc3(val)\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c6efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up necessary auxilaries for neural net training\n",
    "model1 = model1()\n",
    "model2 = model2()\n",
    "model3 = model3()\n",
    "model4 = model4()\n",
    "model5 = model5()\n",
    "costFunc = nn.CrossEntropyLoss()\n",
    "model1Opt = optim.Adam(model1.parameters(), lr=0.001)\n",
    "model2Opt = optim.Adam(model2.parameters(), lr=0.001)\n",
    "model3Opt = optim.Adam(model3.parameters(), lr=0.001)\n",
    "model4Opt = optim.Adam(model4.parameters(), lr=0.001)\n",
    "model5Opt = optim.Adam(model5.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all 5 models using different batch sizes\n",
    "EPOCHS = 40\n",
    "for index in range(EPOCHS):\n",
    "    # model 1\n",
    "    for batch in train1:\n",
    "        inputImages, groundTruth = batch\n",
    "        model1.zero_grad()\n",
    "        output = model1(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost.backward()\n",
    "        model1Opt.step()\n",
    "\n",
    "    # model 2\n",
    "    for batch in train2:\n",
    "        inputImages, groundTruth = batch\n",
    "        model2.zero_grad()\n",
    "        output = model2(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost.backward()\n",
    "        model2Opt.step()\n",
    "        \n",
    "    # model 3\n",
    "    for batch in train3:\n",
    "        inputImages, groundTruth = batch\n",
    "        model3.zero_grad()\n",
    "        output = model3(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost.backward()\n",
    "        model3Opt.step()\n",
    "        \n",
    "    # model 4\n",
    "    for batch in train4:\n",
    "        inputImages, groundTruth = batch\n",
    "        model4.zero_grad()\n",
    "        output = model4(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost.backward()\n",
    "        model4Opt.step()\n",
    "            \n",
    "    # model 5\n",
    "    for batch in train5:\n",
    "        inputImages, groundTruth = batch\n",
    "        model5.zero_grad()\n",
    "        output = model5(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost.backward()\n",
    "        model5Opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5602e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss and accuracy for every model for training set\n",
    "train_cost_list = []\n",
    "train_List = []\n",
    "\n",
    "# model 1\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "cc = 0\n",
    "with torch.no_grad():\n",
    "    for batch in train1:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model1(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        cc += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "train_cost_list.append(cost_tot / cc)\n",
    "train_List.append(round(corr/total, 3)) \n",
    "\n",
    "# model 2\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "cc = 0\n",
    "with torch.no_grad():\n",
    "    for batch in train2:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model2(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        cc += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "train_cost_list.append(cost_tot / cc)\n",
    "train_List.append(round(corr/total, 3)) \n",
    "\n",
    "# model 3\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "cc = 0\n",
    "with torch.no_grad():\n",
    "    for batch in train3:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model3(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        cc += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "train_cost_list.append(cost_tot / cc)\n",
    "train_List.append(round(corr/total, 3)) \n",
    "\n",
    "# model 4\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "cc = 0\n",
    "with torch.no_grad():\n",
    "    for batch in train4:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model4(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        cc += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "train_cost_list.append(cost_tot / cc)\n",
    "train_List.append(round(corr/total, 3)) \n",
    "\n",
    "# model 5\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "cc = 0\n",
    "with torch.no_grad():\n",
    "    for batch in train5:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model5(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        cc += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "train_cost_list.append(cost_tot / cc)\n",
    "train_List.append(round(corr/total, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3657062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss and accuracy for every model for testing set\n",
    "testCostList = []\n",
    "testAccList = []\n",
    "\n",
    "# model 1\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "costCounter = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test1:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model1(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        costCounter += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "testCostList.append(cost_tot / costCounter)\n",
    "testAccList.append(round(corr/total, 3))\n",
    "\n",
    "# model 2\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "costCounter = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test2:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model2(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        costCounter += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "testCostList.append(cost_tot / costCounter)\n",
    "testAccList.append(round(corr/total, 3))\n",
    "\n",
    "# model 3\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "costCounter = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test3:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model3(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        costCounter += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "testCostList.append(cost_tot / costCounter)\n",
    "testAccList.append(round(corr/total, 3))\n",
    "\n",
    "# model 4\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "costCounter = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test4:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model4(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        costCounter += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "testCostList.append(cost_tot / costCounter)\n",
    "testAccList.append(round(corr/total, 3))\n",
    "\n",
    "# model 5\n",
    "corr = 0\n",
    "total = 0\n",
    "cost_tot = 0\n",
    "costCounter = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test5:\n",
    "        inputImages, groundTruth = batch\n",
    "        output = model5(inputImages.view(-1,784))\n",
    "        cost = costFunc(output, groundTruth)\n",
    "        cost_tot += cost\n",
    "        costCounter += 1\n",
    "        for i, outputTensor in enumerate(output):\n",
    "            if torch.argmax(outputTensor) == groundTruth[i]:\n",
    "                corr += 1\n",
    "            total += 1\n",
    "testCostList.append(cost_tot / costCounter)\n",
    "testAccList.append(round(corr/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb014f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sensitivity of every model\n",
    "sensitivityList = []\n",
    "\n",
    "# model 1\n",
    "# Get gradient norm (From slides)\n",
    "gradAll = 0.0\n",
    "fNormAll = 0\n",
    "counter = 0\n",
    "for p in model1.parameters():\n",
    "    grad = 0.0\n",
    "    if p.grad is not None:\n",
    "        grad = p.grad\n",
    "        # Calculate Frobenius norm of gradients\n",
    "        fNorm = torch.linalg.norm(grad).numpy()\n",
    "        fNormAll += fNorm\n",
    "        counter += 1\n",
    "sensitivityList.append(fNormAll / counter)\n",
    "\n",
    "\n",
    "# model 2\n",
    "gradAll = 0.0\n",
    "fNormAll = 0\n",
    "counter = 0\n",
    "for p in model2.parameters():\n",
    "    grad = 0.0\n",
    "    if p.grad is not None:\n",
    "        grad = p.grad\n",
    "        fNorm = torch.linalg.norm(grad).numpy()\n",
    "        fNormAll += fNorm\n",
    "        counter += 1\n",
    "sensitivityList.append(fNormAll / counter)\n",
    "\n",
    "# model 3\n",
    "gradAll = 0.0\n",
    "fNormAll = 0\n",
    "counter = 0\n",
    "for p in model3.parameters():\n",
    "    grad = 0.0\n",
    "    if p.grad is not None:\n",
    "        grad = p.grad\n",
    "        fNorm = torch.linalg.norm(grad).numpy()\n",
    "        fNormAll += fNorm\n",
    "        counter += 1\n",
    "sensitivityList.append(fNormAll / counter)\n",
    "\n",
    "# model 4\n",
    "gradAll = 0.0\n",
    "fNormAll = 0\n",
    "counter = 0\n",
    "for p in model4.parameters():\n",
    "    grad = 0.0\n",
    "    if p.grad is not None:\n",
    "        grad = p.grad\n",
    "        fNorm = torch.linalg.norm(grad).numpy()\n",
    "        fNormAll += fNorm\n",
    "        counter += 1\n",
    "sensitivityList.append(fNormAll / counter)\n",
    "\n",
    "# model 5\n",
    "gradAll = 0.0\n",
    "fNormAll = 0\n",
    "counter = 0\n",
    "for p in model5.parameters():\n",
    "    grad = 0.0\n",
    "    if p.grad is not None:\n",
    "        grad = p.grad\n",
    "        fNorm = torch.linalg.norm(grad).numpy()\n",
    "        fNormAll += fNorm\n",
    "        counter += 1\n",
    "sensitivityList.append(fNormAll / counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaize Accuracy and Sensitivity by batch size of model\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(batchSizes, train_List, 'b', label='Train')\n",
    "ax1.plot(batchSizes, testAccList, 'b--', label='Test')\n",
    "ax2.plot(batchSizes, sensitivityList, 'r', label='Sensitivity')\n",
    "ax1.set_title('Effect of Batch Size on Accuracy and Sensitivity')\n",
    "ax1.set_xlabel('Batch Sizes')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('Accuracy', color='b')\n",
    "ax2.set_ylabel('Sensitivity', color='r')\n",
    "ax1.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e48336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaize Loss and Sensitivity by batch size of model\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(batchSizes, train_cost_list, 'b', label='Train')\n",
    "ax1.plot(batchSizes, testCostList, 'b--', label='Test')\n",
    "ax2.plot(batchSizes, sensitivityList, 'r', label='Sensitivity')\n",
    "ax1.set_title('Effect of Batch Size on Loss and Sensitivity')\n",
    "ax1.set_xlabel('Batch Sizes')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('Loss', color='b')\n",
    "ax2.set_ylabel('Sensitivity', color='r')\n",
    "ax1.legend(loc='upper center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e2afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
